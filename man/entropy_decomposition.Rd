% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/entropy_decomposition.R
\name{entropy_decomposition}
\alias{entropy_decomposition}
\title{Entropy Decoposition Theorem}
\usage{
entropy_decomposition(data, groups)
}
\arguments{
\item{data}{Vector of elements.}

\item{groups}{Vector that describes how the elements in the data can be
aggregated in groups.}
}
\value{
A list with four elements. The information entropy level of the vector.
}
\description{
The function will return the information entropy of a given vector of
frequences decomposed in two parts: a between-groups and a within-groups one.
Moreover, it provides you also the probability of each group and the
entropy of each of the groups.
}
\details{
The total (undecomposed) entropy is equal to the sum of the two
decomposed components. The within-groups component is equal to the weighted
average of the entropy of each of the groups. So the between-groups component
is equal to the residual entropy.
}
\examples{
etpy_decomp <- entropy_decomposition(data, grps)
etpy_decomp <- entropy_decomposition(table(data), grps)
}
