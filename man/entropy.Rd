% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/entropy.R
\encoding{UTF-8}
\name{entropy}
\alias{entropy}
\title{Information Entropy}
\usage{
entropy(data)
}
\arguments{
\item{data}{Numerical vector whos elements are the numerosity of each
of the types in which the observations can be categorised (absolute
frequences).}
}
\value{
The information entropy level of the vector.
}
\description{
The function will return the information entropy of a given vector that
reports the absolute frequency of each of the possible types/groups of
observations of the database.
}
\details{
The function will return the information entropy of a given vector
that reports the absolute frequency of each of the possible types/groups of
observations of the database.
It is also used internally by the entropy decomposition functions.
}
\examples{
etpy <- entropy(c(1,3,5,2,4,9,1,6,10))
}
\references{
Shannon (1948) ``A Mathematical Theory of Communication'', \emph{Bell
System Technical Journal}, 27, 379--423;

Theil (1967) \emph{Economics and Information Theory}, North-Holland;

Theil (1972) \emph{Statistical Decomposition Analysis}, North-Holland;

Frenken (2007) ``Entropy Statistics and Information Theory'', in
Hanusch and Pyka (Eds.) \emph{Elgar Companion to Neo-Schumpeterian
Economics}, Edward Elgar.
}
